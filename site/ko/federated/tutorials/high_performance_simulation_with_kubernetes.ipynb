{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqjnBbmi8BPM"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PTdfUcwp8Eru"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grBmytrShbUE"
      },
      "source": [
        "# High-Performance Simulation with Kubernetes\n",
        "\n",
        "---\n",
        "\n",
        "This tutorial will describe how to set up high-performance simulation using a TFF runtime deployed on Kubernetes.\n",
        "\n",
        "For demonstrative purposes, we'll use the TFF simulation for image classification from the tutorial, [Federated Learning for Image Classification](https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification), but we'll run it against a multi-machine setup consisting of two TFF workers running in Kubernetes. We'll use the same [EMNIST dataset](https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification#preparing_the_input_data) for training, but split into two partitions, one for each TFF worker.\n",
        "\n",
        "This tutorial refers to the following Google Cloud services,\n",
        "\n",
        "- [GKE](https://cloud.google.com/kubernetes-engine/) to create the Kubernetes cluster, but all the steps after the cluster is created can be used with any Kubernetes installation.\n",
        "- [Filestore](https://cloud.google.com/filestore) to serve the training data, but works with any storage medium that can be mounted as a Kubernetes [persistent volume](https://kubernetes.io/docs/concepts/storage/persistent-volumes/).\n",
        "\n",
        "> **Note:** This tutorial assumes you have an existing GCP project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyXVaj0dknQw"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/federated/tutorials/high_performance_simulation_with_kubernetes\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\"> TensorFlow.org에서 보기</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/federated/blob/v0.43.0/docs/tutorials/high_performance_simulation_with_kubernetes.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab에서 실행하기</a>\n",
        "</td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/federated/blob/v0.43.0/docs/tutorials/high_performance_simulation_with_kubernetes.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub에서 소그 보기</a></td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ko/federated/tutorials/high_performance_simulation_with_kubernetes.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Download notebook</a>   </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiq_MY4LopET"
      },
      "source": [
        "## Launch the TFF Workers on Kubernetes\n",
        "\n",
        "### Kubernetes 클러스터 생성하기\n",
        "\n",
        "[worker_service.py](https://github.com/tensorflow/federated/blob/main/docs/tutorials/high_performance_simulation_with_kubernetes/worker_service.py) contains the source code for our custom TFF worker. It runs a simulation server with custom logic for loading a dataset partition and sampling from it for each round of federated learning. (To learn more, see [Loading Remote Data in TFF](https://www.tensorflow.org/federated/tutorials/loading_remote_data).)\n",
        "\n",
        "We're going to deploy our TFF worker as a containerized application on Kubernetes. Lets start by building a Docker image. Using this [Dockerfile](https://github.com/tensorflow/federated/blob/main/docs/tutorials/high_performance_simulation_with_kubernetes/Dockerfile), we can package the code by running,\n",
        "\n",
        "```\n",
        "$ WORKER_IMAGE=tff-worker-service:latest\n",
        "\n",
        "$ docker build --tag $WORKER_IMAGE --file \"./Dockerfile\" .\n",
        "```\n",
        "\n",
        "(Assuming [worker_service.py](https://github.com/tensorflow/federated/blob/main/docs/tutorials/high_performance_simulation_with_kubernetes/worker_service.py) and [Dockerfile](https://github.com/tensorflow/federated/blob/main/docs/tutorials/high_performance_simulation_with_kubernetes/Dockerfile) are located in your working directory.)\n",
        "\n",
        "Then publish the image to a container repository where it can be accessed by the Kubernetes cluster we're about to create, e.g.,\n",
        "\n",
        "```\n",
        "$ docker push $WORKER_IMAGE\n",
        "```\n",
        "\n",
        "### Create a Kubernetes Cluster\n",
        "\n",
        "다음 단계는 한 번만 수행하면 됩니다. 클러스터는 향후 워크로드에 재사용할 수 있습니다.\n",
        "\n",
        "Follow the GKE instructions to [create a cluster](https://cloud.google.com/kubernetes-engine/docs/how-to/persistent-volumes/filestore-csi-driver#enabling_the_on_a_new_cluster) with Filestore CSI driver enabled, e.g.,\n",
        "\n",
        "```\n",
        "gcloud container clusters create tff-cluster --addons=GcpFilestoreCsiDriver\n",
        "```\n",
        "\n",
        "GCP와 상호 작용하는 명령은 [로컬](https://cloud.google.com/kubernetes-engine/docs/tutorials/hello-app#option_b_use_command-line_tools_locally) 또는 [Google Cloud Shell](https://cloud.google.com/shell/)에서 실행할 수 있습니다. 추가 설정이 필요하지 않으므로 Google Cloud Shell을 사용하는 것이 좋습니다.\n",
        "\n",
        "The rest of this tutorial assumes that the cluster is named `tff-cluster`, but the actual name isn't important.\n",
        "\n",
        "### TFF 작업자 애플리케이션 배포하기\n",
        "\n",
        "[worker_deployment.yaml](https://github.com/tensorflow/federated/blob/main/docs/tutorials/high_performance_simulation_with_kubernetes/worker_deployment.yaml) declares the configuration for standing up two TFF workers, each in their own Kubernetes pod with two replicas each. We can apply this configuration to our running cluster,\n",
        "\n",
        "```\n",
        "kubectl apply -f worker_deployment.yaml\n",
        "```\n",
        "\n",
        "Once the changes have been requested, you can check the pods are ready,\n",
        "\n",
        "```\n",
        "kubectl get pod\n",
        "NAME                                        READY   STATUS    RESTARTS   AGE\n",
        "tff-workers-deployment-1-6bb8d458d5-hjl9d   1/1     Running   0          5m\n",
        "tff-workers-deployment-1-6bb8d458d5-jgt4b   1/1     Running   0          5m\n",
        "tff-workers-deployment-2-6cb76c6f5d-hqt88   1/1     Running   0          5m\n",
        "tff-workers-deployment-2-6cb76c6f5d-xk92h   1/1     Running   0          5m\n",
        "```\n",
        "\n",
        "Each worker instance runs behind a load balancer with an endpoint. Look up the external IP address of the load balancers,\n",
        "\n",
        "```\n",
        "kubectl get service\n",
        "NAME                    TYPE           CLUSTER-IP    EXTERNAL-IP     PORT(S)        AGE\n",
        "tff-workers-service-1   LoadBalancer   XX.XX.X.XXX   XX.XXX.XX.XXX   80:31830/TCP   6m\n",
        "tff-workers-service-2   LoadBalancer   XX.XX.X.XXX   XX.XXX.XX.XXX   80:31319/TCP   6m\n",
        "```\n",
        "\n",
        "You'll need it later to connect the training loop to the running workers.\n",
        "\n",
        "> **참고:** 이렇게 하면 배포가 인터넷에 노출되며 데모용으로만 사용됩니다. 운영 용도의 경우, 방화벽과 인증을 강력히 권장합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pyq4xsa6BJ3Q"
      },
      "source": [
        "## Prepare Training Data\n",
        "\n",
        "\n",
        "The EMNIST partitions we'll consume for training can be downloaded from TFF's public [dataset repository](https://console.cloud.google.com/storage/browser/tff-datasets-public/emnist-partitions/2-partition), \n",
        "\n",
        "```\n",
        "gsutil cp -r gs://tff-datasets-public/emnist-partitions/2-partition\n",
        "```\n",
        "\n",
        "You can then upload them to each pod by copying them to a replica, e.g.,\n",
        "\n",
        "```\n",
        "kubectl cp emnist_part_1.sqlite tff-workers-deployment-1-6bb8d458d5-hjl9d:/root/worker/data/emnist_partition.sqlite\n",
        "\n",
        "kubectl cp emnist_part_2.sqlite tff-workers-deployment-2-6cb76c6f5d-hqt88:/root/worker/data/emnist_partition.sqlite\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zFenI3IPpgI"
      },
      "source": [
        "## Run Simulation\n",
        "\n",
        "Now we're ready to run simulations against our cluster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-q80uOHl4dg"
      },
      "source": [
        "### Setup TFF Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ke7EyuvG0Zyn"
      },
      "outputs": [],
      "source": [
        "#@test {\"skip\": true}\n",
        "!pip install --quiet --upgrade tensorflow-federated\n",
        "!pip install --quiet --upgrade nest-asyncio\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFkcJZAojZDm"
      },
      "source": [
        "### Define the Training Procedure\n",
        "\n",
        "The following defines the dataset iteration methodology, the model architecture, and the round-over-round process for federated learning. (For more [detail](https://www.tensorflow.org/federated/tutorials/loading_remote_data#training_the_model).)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0Qk0sCDZUQR"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "\n",
        "source, _ = tff.simulation.datasets.emnist.load_data()\n",
        "\n",
        "\n",
        "def map_fn(example):\n",
        "  return collections.OrderedDict(\n",
        "      x=tf.reshape(example['pixels'], [-1, 784]), y=example['label'])\n",
        "\n",
        "\n",
        "def client_data(n):\n",
        "  ds = source.create_tf_dataset_for_client(source.client_ids[n])\n",
        "  return ds.repeat(10).batch(20).map(map_fn)\n",
        "\n",
        "\n",
        "train_data = [client_data(n) for n in range(10)]\n",
        "input_spec = train_data[0].element_spec\n",
        "\n",
        "\n",
        "def model_fn():\n",
        "  model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.InputLayer(input_shape=(784,)),\n",
        "      tf.keras.layers.Dense(units=10, kernel_initializer='zeros'),\n",
        "      tf.keras.layers.Softmax(),\n",
        "  ])\n",
        "  return tff.learning.from_keras_model(\n",
        "      model,\n",
        "      input_spec=input_spec,\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "\n",
        "\n",
        "trainer = tff.learning.build_federated_averaging_process(\n",
        "    model_fn, client_optimizer_fn=lambda: tf.keras.optimizers.SGD(0.02))\n",
        "\n",
        "\n",
        "def evaluate(num_rounds=10):\n",
        "  state = trainer.initialize()\n",
        "  for round in range(num_rounds):\n",
        "    t1 = time.time()\n",
        "    state, metrics = trainer.next(state, train_data)\n",
        "    t2 = time.time()\n",
        "    print('Round {}: loss {}, round time {}'.format(round, metrics.loss, t2 - t1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5OhgAp7jrNI"
      },
      "source": [
        "### Connect to TFF Workers\n",
        "\n",
        "By default, TFF executes all computations locally. In this step we tell TFF to connect to the Kubernetes services we set up above. Be sure to copy the external IP addresses of your services here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXSLXwcdciYm"
      },
      "outputs": [],
      "source": [
        "import grpc\n",
        "\n",
        "ip_address_1 = '0.0.0.0'  #@param {type:\"string\"}\n",
        "ip_address_2 = '0.0.0.0'  #@param {type:\"string\"}\n",
        "port = 80\n",
        "\n",
        "channels = [\n",
        "    grpc.insecure_channel(f'{ip_address_1}:{port}'),\n",
        "    grpc.insecure_channel(f'{ip_address_2}:{port}')\n",
        "]\n",
        "\n",
        "tff.backends.native.set_remote_python_execution_context(channels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEgpmgSRktJY"
      },
      "source": [
        "### Execute Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mw92IA6_Zrud"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "round  1, metrics=OrderedDict([('sparse_categorical_accuracy', 0.10557769), ('loss', 12.475689), ('num_examples', 5020), ('num_batches', 5020)])\n",
            "round  2, metrics=OrderedDict([('sparse_categorical_accuracy', 0.11940298), ('loss', 10.497084), ('num_examples', 5360), ('num_batches', 5360)])\n",
            "round  3, metrics=OrderedDict([('sparse_categorical_accuracy', 0.16223507), ('loss', 7.569645), ('num_examples', 5190), ('num_batches', 5190)])\n",
            "round  4, metrics=OrderedDict([('sparse_categorical_accuracy', 0.2648384), ('loss', 6.0947175), ('num_examples', 5105), ('num_batches', 5105)])\n",
            "round  5, metrics=OrderedDict([('sparse_categorical_accuracy', 0.29003084), ('loss', 6.2815433), ('num_examples', 4865), ('num_batches', 4865)])\n",
            "round  6, metrics=OrderedDict([('sparse_categorical_accuracy', 0.40237388), ('loss', 4.630901), ('num_examples', 5055), ('num_batches', 5055)])\n",
            "round  7, metrics=OrderedDict([('sparse_categorical_accuracy', 0.4288425), ('loss', 4.2358975), ('num_examples', 5270), ('num_batches', 5270)])\n",
            "round  8, metrics=OrderedDict([('sparse_categorical_accuracy', 0.46349892), ('loss', 4.3829923), ('num_examples', 4630), ('num_batches', 4630)])\n",
            "round  9, metrics=OrderedDict([('sparse_categorical_accuracy', 0.492094), ('loss', 3.8121278), ('num_examples', 4680), ('num_batches', 4680)])\n",
            "round 10, metrics=OrderedDict([('sparse_categorical_accuracy', 0.5872674), ('loss', 3.058461), ('num_examples', 5105), ('num_batches', 5105)])\n"
          ]
        }
      ],
      "source": [
        "evaluate()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "high_performance_simulation_with_kubernetes.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
